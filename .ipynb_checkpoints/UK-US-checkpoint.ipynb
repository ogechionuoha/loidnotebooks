{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process data\n",
    "preprocessor = keras.applications.resnet50.preprocess_input\n",
    "data_generator = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocessor, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 images belonging to 2 classes.\n",
      "Found 12000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../images/uk_us/train'\n",
    "training_set = data_generator.flow_from_directory(data_folder, class_mode='binary',\n",
    "                                                 target_size=(img_height,img_width),\n",
    "                                                 subset=\"training\", shuffle=True, seed=666,\n",
    "                                                  batch_size=batch_size)\n",
    "validation_set = data_generator.flow_from_directory(data_folder, class_mode='binary',\n",
    "                                                    target_size=(img_height,img_width),\n",
    "                                                    subset=\"validation\", shuffle=True, seed=666,\n",
    "                                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Get pretrained model\n",
    "resnet_model = tf.keras.applications.ResNet50(input_shape=(img_width, img_height, 3), include_top=False, pooling='avg', weights='imagenet')\n",
    "resnet_model.trainable = False\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and set params\n",
    "model = keras.models.Sequential([resnet_model, keras.layers.Dense(1, name='logits'), keras.layers.Sigmoid(name='sigmoid_out')])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "loss = keras.losses.BinaryCrossentropy()#from_logits=True)\n",
    "checkpoint = ModelCheckpoint('./model_checkpoints/uk_us/new_location_classifier', save_weights_only=True, monitor=\"val_loss\", save_best_only=True)\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='bin_accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.Accuracy(name='accuracy'),\n",
    "    keras.metrics.MeanAbsoluteError(name='mae')\n",
    "]\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 3788s 5s/step - loss: 0.6383 - tp: 8369.6844 - fp: 4673.8549 - tn: 7329.7457 - fn: 3690.6298 - bin_accuracy: 0.6345 - precision: 0.6248 - recall: 0.6653 - auc: 0.6842 - accuracy: 0.0000e+00 - mae: 0.4434 - val_loss: 0.5763 - val_tp: 2750.0000 - val_fp: 580.0000 - val_tn: 5420.0000 - val_fn: 3250.0000 - val_bin_accuracy: 0.6808 - val_precision: 0.8258 - val_recall: 0.4583 - val_auc: 0.8237 - val_accuracy: 0.0000e+00 - val_mae: 0.3928\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 4118s 5s/step - loss: 0.5647 - tp: 8987.8509 - fp: 4004.9547 - tn: 8024.3688 - fn: 3046.7403 - bin_accuracy: 0.7062 - precision: 0.6925 - recall: 0.7459 - auc: 0.7778 - accuracy: 0.0000e+00 - mae: 0.3951 - val_loss: 0.5054 - val_tp: 4887.0000 - val_fp: 1730.0000 - val_tn: 4270.0000 - val_fn: 1113.0000 - val_bin_accuracy: 0.7631 - val_precision: 0.7386 - val_recall: 0.8145 - val_auc: 0.8420 - val_accuracy: 0.0000e+00 - val_mae: 0.3613\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 4089s 5s/step - loss: 0.5422 - tp: 9128.1119 - fp: 3759.8269 - tn: 8285.2104 - fn: 2890.7656 - bin_accuracy: 0.7216 - precision: 0.7067 - recall: 0.7551 - auc: 0.8005 - accuracy: 0.0000e+00 - mae: 0.3787 - val_loss: 0.5064 - val_tp: 4099.0000 - val_fp: 964.0000 - val_tn: 5036.0000 - val_fn: 1901.0000 - val_bin_accuracy: 0.7613 - val_precision: 0.8096 - val_recall: 0.6832 - val_auc: 0.8510 - val_accuracy: 0.0000e+00 - val_mae: 0.3562\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 4088s 5s/step - loss: 0.5264 - tp: 9321.6911 - fp: 3582.9467 - tn: 8428.2290 - fn: 2731.0479 - bin_accuracy: 0.7370 - precision: 0.7228 - recall: 0.7683 - auc: 0.8164 - accuracy: 0.0000e+00 - mae: 0.3670 - val_loss: 0.5246 - val_tp: 3359.0000 - val_fp: 616.0000 - val_tn: 5384.0000 - val_fn: 2641.0000 - val_bin_accuracy: 0.7286 - val_precision: 0.8450 - val_recall: 0.5598 - val_auc: 0.8560 - val_accuracy: 0.0000e+00 - val_mae: 0.3561\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 4075s 5s/step - loss: 0.5119 - tp: 9344.2663 - fp: 3460.2597 - tn: 8610.6605 - fn: 2648.7284 - bin_accuracy: 0.7452 - precision: 0.7291 - recall: 0.7788 - auc: 0.8282 - accuracy: 0.0000e+00 - mae: 0.3569 - val_loss: 0.5567 - val_tp: 5770.0000 - val_fp: 3255.0000 - val_tn: 2745.0000 - val_fn: 230.0000 - val_bin_accuracy: 0.7096 - val_precision: 0.6393 - val_recall: 0.9617 - val_auc: 0.8598 - val_accuracy: 0.0000e+00 - val_mae: 0.3439\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 4076s 5s/step - loss: 0.5105 - tp: 9485.8083 - fp: 3479.3835 - tn: 8482.1931 - fn: 2616.5300 - bin_accuracy: 0.7434 - precision: 0.7279 - recall: 0.7817 - auc: 0.8279 - accuracy: 0.0000e+00 - mae: 0.3515 - val_loss: 0.4718 - val_tp: 4868.0000 - val_fp: 1476.0000 - val_tn: 4524.0000 - val_fn: 1132.0000 - val_bin_accuracy: 0.7827 - val_precision: 0.7673 - val_recall: 0.8113 - val_auc: 0.8618 - val_accuracy: 0.0000e+00 - val_mae: 0.3309\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 4062s 5s/step - loss: 0.4970 - tp: 9479.4967 - fp: 3303.3648 - tn: 8725.8855 - fn: 2555.1678 - bin_accuracy: 0.7587 - precision: 0.7440 - recall: 0.7890 - auc: 0.8406 - accuracy: 0.0000e+00 - mae: 0.3447 - val_loss: 0.4714 - val_tp: 4504.0000 - val_fp: 1106.0000 - val_tn: 4894.0000 - val_fn: 1496.0000 - val_bin_accuracy: 0.7832 - val_precision: 0.8029 - val_recall: 0.7507 - val_auc: 0.8653 - val_accuracy: 0.0000e+00 - val_mae: 0.3285\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 4067s 5s/step - loss: 0.4971 - tp: 9473.7949 - fp: 3301.5699 - tn: 8732.5007 - fn: 2556.0493 - bin_accuracy: 0.7571 - precision: 0.7421 - recall: 0.7885 - auc: 0.8392 - accuracy: 0.0000e+00 - mae: 0.3421 - val_loss: 0.4698 - val_tp: 5292.0000 - val_fp: 1965.0000 - val_tn: 4035.0000 - val_fn: 708.0000 - val_bin_accuracy: 0.7772 - val_precision: 0.7292 - val_recall: 0.8820 - val_auc: 0.8669 - val_accuracy: 0.0000e+00 - val_mae: 0.3204\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 4054s 5s/step - loss: 0.4892 - tp: 9509.8788 - fp: 3212.1172 - tn: 8837.7430 - fn: 2504.1758 - bin_accuracy: 0.7613 - precision: 0.7471 - recall: 0.7897 - auc: 0.8450 - accuracy: 0.0000e+00 - mae: 0.3359 - val_loss: 0.4786 - val_tp: 5465.0000 - val_fp: 2202.0000 - val_tn: 3798.0000 - val_fn: 535.0000 - val_bin_accuracy: 0.7719 - val_precision: 0.7128 - val_recall: 0.9108 - val_auc: 0.8678 - val_accuracy: 0.0000e+00 - val_mae: 0.3196\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 4095s 5s/step - loss: 0.4802 - tp: 9645.9774 - fp: 3132.7790 - tn: 8855.4514 - fn: 2429.7071 - bin_accuracy: 0.7668 - precision: 0.7529 - recall: 0.7990 - auc: 0.8529 - accuracy: 0.0000e+00 - mae: 0.3318 - val_loss: 0.4560 - val_tp: 4985.0000 - val_fp: 1472.0000 - val_tn: 4528.0000 - val_fn: 1015.0000 - val_bin_accuracy: 0.7928 - val_precision: 0.7720 - val_recall: 0.8308 - val_auc: 0.8701 - val_accuracy: 0.0000e+00 - val_mae: 0.3149\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 2990s 4s/step - loss: 0.4806 - tp: 9593.5752 - fp: 3118.5992 - tn: 8896.5925 - fn: 2455.1478 - bin_accuracy: 0.7705 - precision: 0.7572 - recall: 0.7972 - auc: 0.8528 - accuracy: 0.0000e+00 - mae: 0.3292 - val_loss: 0.4593 - val_tp: 5228.0000 - val_fp: 1758.0000 - val_tn: 4242.0000 - val_fn: 772.0000 - val_bin_accuracy: 0.7892 - val_precision: 0.7484 - val_recall: 0.8713 - val_auc: 0.8711 - val_accuracy: 0.0000e+00 - val_mae: 0.3139\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 2261s 3s/step - loss: 0.4744 - tp: 9571.2144 - fp: 3042.7643 - tn: 8976.1917 - fn: 2473.7443 - bin_accuracy: 0.7731 - precision: 0.7608 - recall: 0.7943 - auc: 0.8561 - accuracy: 0.0000e+00 - mae: 0.3258 - val_loss: 0.4600 - val_tp: 5301.0000 - val_fp: 1857.0000 - val_tn: 4143.0000 - val_fn: 699.0000 - val_bin_accuracy: 0.7870 - val_precision: 0.7406 - val_recall: 0.8835 - val_auc: 0.8717 - val_accuracy: 0.0000e+00 - val_mae: 0.3100\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 2239s 3s/step - loss: 0.4734 - tp: 9600.0453 - fp: 3036.4434 - tn: 9005.7031 - fn: 2421.7230 - bin_accuracy: 0.7729 - precision: 0.7592 - recall: 0.7986 - auc: 0.8567 - accuracy: 0.0000e+00 - mae: 0.3241 - val_loss: 0.4630 - val_tp: 5403.0000 - val_fp: 2012.0000 - val_tn: 3988.0000 - val_fn: 597.0000 - val_bin_accuracy: 0.7826 - val_precision: 0.7287 - val_recall: 0.9005 - val_auc: 0.8735 - val_accuracy: 0.0000e+00 - val_mae: 0.3089\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 3606s 5s/step - loss: 0.4684 - tp: 9616.0426 - fp: 3036.7723 - tn: 8980.6059 - fn: 2430.4940 - bin_accuracy: 0.7745 - precision: 0.7617 - recall: 0.8011 - auc: 0.8604 - accuracy: 0.0000e+00 - mae: 0.3215 - val_loss: 0.4494 - val_tp: 5142.0000 - val_fp: 1567.0000 - val_tn: 4433.0000 - val_fn: 858.0000 - val_bin_accuracy: 0.7979 - val_precision: 0.7664 - val_recall: 0.8570 - val_auc: 0.8746 - val_accuracy: 0.0000e+00 - val_mae: 0.3064\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 4048s 5s/step - loss: 0.4658 - tp: 9590.1625 - fp: 2967.5379 - tn: 9091.3063 - fn: 2414.9081 - bin_accuracy: 0.7775 - precision: 0.7645 - recall: 0.8010 - auc: 0.8627 - accuracy: 0.0000e+00 - mae: 0.3201 - val_loss: 0.4618 - val_tp: 5429.0000 - val_fp: 2029.0000 - val_tn: 3971.0000 - val_fn: 571.0000 - val_bin_accuracy: 0.7833 - val_precision: 0.7279 - val_recall: 0.9048 - val_auc: 0.8752 - val_accuracy: 0.0000e+00 - val_mae: 0.3057\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 4059s 5s/step - loss: 0.4669 - tp: 9638.4381 - fp: 2939.5419 - tn: 9105.8096 - fn: 2380.1252 - bin_accuracy: 0.7780 - precision: 0.7653 - recall: 0.8005 - auc: 0.8609 - accuracy: 0.0000e+00 - mae: 0.3171 - val_loss: 0.4865 - val_tp: 5643.0000 - val_fp: 2433.0000 - val_tn: 3567.0000 - val_fn: 357.0000 - val_bin_accuracy: 0.7675 - val_precision: 0.6987 - val_recall: 0.9405 - val_auc: 0.8757 - val_accuracy: 0.0000e+00 - val_mae: 0.3099\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 4046s 5s/step - loss: 0.4592 - tp: 9761.9161 - fp: 2916.1838 - tn: 9082.3435 - fn: 2303.4714 - bin_accuracy: 0.7837 - precision: 0.7711 - recall: 0.8118 - auc: 0.8673 - accuracy: 0.0000e+00 - mae: 0.3151 - val_loss: 0.4448 - val_tp: 5039.0000 - val_fp: 1455.0000 - val_tn: 4545.0000 - val_fn: 961.0000 - val_bin_accuracy: 0.7987 - val_precision: 0.7759 - val_recall: 0.8398 - val_auc: 0.8765 - val_accuracy: 0.0000e+00 - val_mae: 0.3041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "186/750 [======>.......................] - ETA: 40:38 - loss: 0.4695 - tp: 2375.7204 - fp: 724.2366 - tn: 2267.4194 - fn: 616.6237 - bin_accuracy: 0.7755 - precision: 0.7669 - recall: 0.7935 - auc: 0.8588 - accuracy: 0.0000e+00 - mae: 0.3200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4051s 5s/step - loss: 0.4609 - tp: 9731.5180 - fp: 2932.7803 - tn: 9045.6285 - fn: 2353.9880 - bin_accuracy: 0.7806 - precision: 0.7705 - recall: 0.8045 - auc: 0.8650 - accuracy: 0.0000e+00 - mae: 0.3138 - val_loss: 0.4398 - val_tp: 4833.0000 - val_fp: 1261.0000 - val_tn: 4739.0000 - val_fn: 1167.0000 - val_bin_accuracy: 0.7977 - val_precision: 0.7931 - val_recall: 0.8055 - val_auc: 0.8786 - val_accuracy: 0.0000e+00 - val_mae: 0.2988\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 4050s 5s/step - loss: 0.4563 - tp: 9748.6831 - fp: 2823.5047 - tn: 9179.0093 - fn: 2312.7177 - bin_accuracy: 0.7851 - precision: 0.7737 - recall: 0.8058 - auc: 0.8683 - accuracy: 0.0000e+00 - mae: 0.3114 - val_loss: 0.4475 - val_tp: 5349.0000 - val_fp: 1804.0000 - val_tn: 4196.0000 - val_fn: 651.0000 - val_bin_accuracy: 0.7954 - val_precision: 0.7478 - val_recall: 0.8915 - val_auc: 0.8796 - val_accuracy: 0.0000e+00 - val_mae: 0.2968\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 4057s 5s/step - loss: 0.4576 - tp: 9726.3236 - fp: 2898.7483 - tn: 9109.6205 - fn: 2329.2224 - bin_accuracy: 0.7814 - precision: 0.7685 - recall: 0.8084 - auc: 0.8669 - accuracy: 0.0000e+00 - mae: 0.3097 - val_loss: 0.4518 - val_tp: 5429.0000 - val_fp: 1909.0000 - val_tn: 4091.0000 - val_fn: 571.0000 - val_bin_accuracy: 0.7933 - val_precision: 0.7398 - val_recall: 0.9048 - val_auc: 0.8800 - val_accuracy: 0.0000e+00 - val_mae: 0.2975\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 4064s 5s/step - loss: 0.4546 - tp: 9827.5846 - fp: 2815.7723 - tn: 9146.1917 - fn: 2274.3662 - bin_accuracy: 0.7882 - precision: 0.7774 - recall: 0.8134 - auc: 0.8696 - accuracy: 0.0000e+00 - mae: 0.3083 - val_loss: 0.4385 - val_tp: 4799.0000 - val_fp: 1217.0000 - val_tn: 4783.0000 - val_fn: 1201.0000 - val_bin_accuracy: 0.7985 - val_precision: 0.7977 - val_recall: 0.7998 - val_auc: 0.8802 - val_accuracy: 0.0000e+00 - val_mae: 0.2992\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 4055s 5s/step - loss: 0.4513 - tp: 9799.1984 - fp: 2818.0213 - tn: 9154.5832 - fn: 2292.1119 - bin_accuracy: 0.7882 - precision: 0.7781 - recall: 0.8118 - auc: 0.8723 - accuracy: 0.0000e+00 - mae: 0.3068 - val_loss: 0.4382 - val_tp: 5195.0000 - val_fp: 1551.0000 - val_tn: 4449.0000 - val_fn: 805.0000 - val_bin_accuracy: 0.8037 - val_precision: 0.7701 - val_recall: 0.8658 - val_auc: 0.8809 - val_accuracy: 0.0000e+00 - val_mae: 0.2939\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 4045s 5s/step - loss: 0.4572 - tp: 9793.0027 - fp: 2867.5366 - tn: 9090.7497 - fn: 2312.6258 - bin_accuracy: 0.7819 - precision: 0.7707 - recall: 0.8098 - auc: 0.8673 - accuracy: 0.0000e+00 - mae: 0.3085 - val_loss: 0.4852 - val_tp: 3634.0000 - val_fp: 572.0000 - val_tn: 5428.0000 - val_fn: 2366.0000 - val_bin_accuracy: 0.7552 - val_precision: 0.8640 - val_recall: 0.6057 - val_auc: 0.8814 - val_accuracy: 0.0000e+00 - val_mae: 0.3154\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 4054s 5s/step - loss: 0.4498 - tp: 9764.9334 - fp: 2802.0306 - tn: 9226.1305 - fn: 2270.8202 - bin_accuracy: 0.7888 - precision: 0.7774 - recall: 0.8104 - auc: 0.8736 - accuracy: 0.0000e+00 - mae: 0.3055 - val_loss: 0.4617 - val_tp: 4055.0000 - val_fp: 717.0000 - val_tn: 5283.0000 - val_fn: 1945.0000 - val_bin_accuracy: 0.7782 - val_precision: 0.8497 - val_recall: 0.6758 - val_auc: 0.8832 - val_accuracy: 0.0000e+00 - val_mae: 0.3038\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 4057s 5s/step - loss: 0.4424 - tp: 9820.9268 - fp: 2774.0333 - tn: 9234.9108 - fn: 2234.0439 - bin_accuracy: 0.7925 - precision: 0.7808 - recall: 0.8185 - auc: 0.8772 - accuracy: 0.0000e+00 - mae: 0.2999 - val_loss: 0.4315 - val_tp: 5012.0000 - val_fp: 1373.0000 - val_tn: 4627.0000 - val_fn: 988.0000 - val_bin_accuracy: 0.8033 - val_precision: 0.7850 - val_recall: 0.8353 - val_auc: 0.8832 - val_accuracy: 0.0000e+00 - val_mae: 0.2910\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 4054s 5s/step - loss: 0.4425 - tp: 9779.8802 - fp: 2775.3116 - tn: 9246.8708 - fn: 2261.8522 - bin_accuracy: 0.7931 - precision: 0.7816 - recall: 0.8138 - auc: 0.8773 - accuracy: 0.0000e+00 - mae: 0.3001 - val_loss: 0.4684 - val_tp: 3904.0000 - val_fp: 658.0000 - val_tn: 5342.0000 - val_fn: 2096.0000 - val_bin_accuracy: 0.7705 - val_precision: 0.8558 - val_recall: 0.6507 - val_auc: 0.8828 - val_accuracy: 0.0000e+00 - val_mae: 0.3080\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 4052s 5s/step - loss: 0.4461 - tp: 9721.6298 - fp: 2746.0120 - tn: 9338.4660 - fn: 2257.8069 - bin_accuracy: 0.7918 - precision: 0.7797 - recall: 0.8099 - auc: 0.8744 - accuracy: 0.0000e+00 - mae: 0.3023 - val_loss: 0.4385 - val_tp: 4527.0000 - val_fp: 991.0000 - val_tn: 5009.0000 - val_fn: 1473.0000 - val_bin_accuracy: 0.7947 - val_precision: 0.8204 - val_recall: 0.7545 - val_auc: 0.8835 - val_accuracy: 0.0000e+00 - val_mae: 0.2956\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 4072s 5s/step - loss: 0.4458 - tp: 9713.3142 - fp: 2743.1904 - tn: 9321.7044 - fn: 2285.7057 - bin_accuracy: 0.7904 - precision: 0.7789 - recall: 0.8079 - auc: 0.8749 - accuracy: 0.0000e+00 - mae: 0.3013 - val_loss: 0.4370 - val_tp: 4561.0000 - val_fp: 1018.0000 - val_tn: 4982.0000 - val_fn: 1439.0000 - val_bin_accuracy: 0.7952 - val_precision: 0.8175 - val_recall: 0.7602 - val_auc: 0.8835 - val_accuracy: 0.0000e+00 - val_mae: 0.2944\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 4079s 5s/step - loss: 0.4445 - tp: 9769.2130 - fp: 2715.2836 - tn: 9302.1678 - fn: 2277.2503 - bin_accuracy: 0.7925 - precision: 0.7834 - recall: 0.8090 - auc: 0.8760 - accuracy: 0.0000e+00 - mae: 0.2998 - val_loss: 0.4325 - val_tp: 5261.0000 - val_fp: 1574.0000 - val_tn: 4426.0000 - val_fn: 739.0000 - val_bin_accuracy: 0.8073 - val_precision: 0.7697 - val_recall: 0.8768 - val_auc: 0.8849 - val_accuracy: 0.0000e+00 - val_mae: 0.2867\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 4067s 5s/step - loss: 0.4415 - tp: 9790.5912 - fp: 2714.0839 - tn: 9315.3116 - fn: 2243.9281 - bin_accuracy: 0.7935 - precision: 0.7819 - recall: 0.8159 - auc: 0.8769 - accuracy: 0.0000e+00 - mae: 0.2977 - val_loss: 0.4271 - val_tp: 4865.0000 - val_fp: 1205.0000 - val_tn: 4795.0000 - val_fn: 1135.0000 - val_bin_accuracy: 0.8050 - val_precision: 0.8015 - val_recall: 0.8108 - val_auc: 0.8859 - val_accuracy: 0.0000e+00 - val_mae: 0.2870\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 4059s 5s/step - loss: 0.4425 - tp: 9725.2344 - fp: 2753.1931 - tn: 9292.4541 - fn: 2293.0333 - bin_accuracy: 0.7895 - precision: 0.7792 - recall: 0.8082 - auc: 0.8760 - accuracy: 0.0000e+00 - mae: 0.2981 - val_loss: 0.4319 - val_tp: 5252.0000 - val_fp: 1569.0000 - val_tn: 4431.0000 - val_fn: 748.0000 - val_bin_accuracy: 0.8069 - val_precision: 0.7700 - val_recall: 0.8753 - val_auc: 0.8852 - val_accuracy: 0.0000e+00 - val_mae: 0.2870\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 4074s 5s/step - loss: 0.4382 - tp: 9753.2716 - fp: 2699.3555 - tn: 9337.4700 - fn: 2273.8176 - bin_accuracy: 0.7940 - precision: 0.7842 - recall: 0.8112 - auc: 0.8797 - accuracy: 0.0000e+00 - mae: 0.2958 - val_loss: 0.4358 - val_tp: 5350.0000 - val_fp: 1699.0000 - val_tn: 4301.0000 - val_fn: 650.0000 - val_bin_accuracy: 0.8043 - val_precision: 0.7590 - val_recall: 0.8917 - val_auc: 0.8858 - val_accuracy: 0.0000e+00 - val_mae: 0.2866\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 4078s 5s/step - loss: 0.4367 - tp: 9768.1438 - fp: 2667.8589 - tn: 9415.3742 - fn: 2212.5379 - bin_accuracy: 0.7983 - precision: 0.7858 - recall: 0.8157 - auc: 0.8809 - accuracy: 0.0000e+00 - mae: 0.2956 - val_loss: 0.4260 - val_tp: 5042.0000 - val_fp: 1358.0000 - val_tn: 4642.0000 - val_fn: 958.0000 - val_bin_accuracy: 0.8070 - val_precision: 0.7878 - val_recall: 0.8403 - val_auc: 0.8865 - val_accuracy: 0.0000e+00 - val_mae: 0.2858\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 4060s 5s/step - loss: 0.4379 - tp: 9781.8083 - fp: 2676.2836 - tn: 9360.8735 - fn: 2244.9494 - bin_accuracy: 0.7964 - precision: 0.7869 - recall: 0.8128 - auc: 0.8793 - accuracy: 0.0000e+00 - mae: 0.2944 - val_loss: 0.4288 - val_tp: 4687.0000 - val_fp: 1071.0000 - val_tn: 4929.0000 - val_fn: 1313.0000 - val_bin_accuracy: 0.8013 - val_precision: 0.8140 - val_recall: 0.7812 - val_auc: 0.8867 - val_accuracy: 0.0000e+00 - val_mae: 0.2883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "750/750 [==============================] - 4062s 5s/step - loss: 0.4392 - tp: 9777.8336 - fp: 2729.8083 - tn: 9306.3755 - fn: 2249.8975 - bin_accuracy: 0.7913 - precision: 0.7797 - recall: 0.8121 - auc: 0.8780 - accuracy: 0.0000e+00 - mae: 0.2946 - val_loss: 0.4299 - val_tp: 4623.0000 - val_fp: 1028.0000 - val_tn: 4972.0000 - val_fn: 1377.0000 - val_bin_accuracy: 0.7996 - val_precision: 0.8181 - val_recall: 0.7705 - val_auc: 0.8869 - val_accuracy: 0.0000e+00 - val_mae: 0.2877\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 4061s 5s/step - loss: 0.4322 - tp: 9842.7883 - fp: 2630.0453 - tn: 9416.6405 - fn: 2174.4407 - bin_accuracy: 0.8010 - precision: 0.7907 - recall: 0.8197 - auc: 0.8835 - accuracy: 0.0000e+00 - mae: 0.2927 - val_loss: 0.4243 - val_tp: 4943.0000 - val_fp: 1246.0000 - val_tn: 4754.0000 - val_fn: 1057.0000 - val_bin_accuracy: 0.8081 - val_precision: 0.7987 - val_recall: 0.8238 - val_auc: 0.8872 - val_accuracy: 0.0000e+00 - val_mae: 0.2846\n",
      "Epoch 38/50\n",
      "186/750 [======>.......................] - ETA: 40:33 - loss: 0.4303 - tp: 2512.5430 - fp: 662.0914 - tn: 2292.3871 - fn: 516.9785 - bin_accuracy: 0.8037 - precision: 0.7936 - recall: 0.8327 - auc: 0.8855 - accuracy: 0.0000e+00 - mae: 0.2911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4084s 5s/step - loss: 0.4350 - tp: 9818.3981 - fp: 2697.0985 - tn: 9332.2130 - fn: 2216.2051 - bin_accuracy: 0.7965 - precision: 0.7841 - recall: 0.8187 - auc: 0.8810 - accuracy: 0.0000e+00 - mae: 0.2921 - val_loss: 0.4311 - val_tp: 4531.0000 - val_fp: 958.0000 - val_tn: 5042.0000 - val_fn: 1469.0000 - val_bin_accuracy: 0.7977 - val_precision: 0.8255 - val_recall: 0.7552 - val_auc: 0.8880 - val_accuracy: 0.0000e+00 - val_mae: 0.2875\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 4053s 5s/step - loss: 0.4332 - tp: 9895.2583 - fp: 2645.2490 - tn: 9336.5393 - fn: 2186.8682 - bin_accuracy: 0.7997 - precision: 0.7899 - recall: 0.8203 - auc: 0.8825 - accuracy: 0.0000e+00 - mae: 0.2908 - val_loss: 0.4240 - val_tp: 5172.0000 - val_fp: 1436.0000 - val_tn: 4564.0000 - val_fn: 828.0000 - val_bin_accuracy: 0.8113 - val_precision: 0.7827 - val_recall: 0.8620 - val_auc: 0.8884 - val_accuracy: 0.0000e+00 - val_mae: 0.2811\n",
      "Epoch 41/50\n",
      " 10/750 [..............................] - ETA: 53:33 - loss: 0.4576 - tp: 131.6000 - fp: 38.8000 - tn: 144.2000 - fn: 37.4000 - bin_accuracy: 0.7866 - precision: 0.7700 - recall: 0.7957 - auc: 0.8722 - accuracy: 0.0000e+00 - mae: 0.2944"
     ]
    }
   ],
   "source": [
    " #train\n",
    "history = model.fit(training_set, epochs=50, validation_data=validation_set, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     || 25.9 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.5.4\n"
     ]
    }
   ],
   "source": [
    "test_folder = '../images/uk_us/test'\n",
    "preprocessor = keras.applications.resnet50.preprocess_input\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocessor)\n",
    "test_set = test_data_generator.flow_from_directory(test_folder, class_mode='binary',target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_checkpoints/uk_us/location_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_info = pd.DataFrame(history.history)\n",
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info.to_csv('./model_checkpoints/uk_us/location_classifier.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
