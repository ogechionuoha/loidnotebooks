{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process data\n",
    "preprocessor = keras.applications.resnet50.preprocess_input\n",
    "data_generator = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocessor, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48000 images belonging to 2 classes.\n",
      "Found 12000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../images/uk_not_uk/train'\n",
    "training_set = data_generator.flow_from_directory(data_folder, class_mode='binary',\n",
    "                                                 target_size=(img_height,img_width),\n",
    "                                                 subset=\"training\", shuffle=True, seed=666,\n",
    "                                                  batch_size=batch_size)\n",
    "validation_set = data_generator.flow_from_directory(data_folder, class_mode='binary',\n",
    "                                                    target_size=(img_height,img_width),\n",
    "                                                    subset=\"validation\", shuffle=True, seed=666,\n",
    "                                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Get pretrained model\n",
    "resnet_model = tf.keras.applications.ResNet50(input_shape=(img_width, img_height, 3), include_top=False, pooling='avg', weights='imagenet')\n",
    "resnet_model.trainable = False\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and set params\n",
    "#model = keras.models.Sequential([resnet_model, keras.layers.Dense(1, name='logits')])\n",
    "model = keras.models.Sequential([resnet_model, keras.layers.Dense(1, name='logits'), keras.layers.Activation('sigmoid',name='sigmoid_out')])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "checkpoint = ModelCheckpoint('./model_checkpoints/uk_not_uk/more_epochs_location_classifier', save_weights_only=True, monitor=\"val_loss\", save_best_only=True)\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.Accuracy(name='accuracy'),\n",
    "    keras.metrics.MeanAbsoluteError(name='mae')\n",
    "]\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5085a06550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load old model weights\n",
    "model.load_weights('./model_checkpoints/uk_not_uk/location_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "750/750 [==============================] - 4092s 5s/step - loss: 0.4829 - tp: 8892.8549 - fp: 2487.2197 - tn: 9553.1531 - fn: 3130.6871 - binary_accuracy: 0.7662 - precision: 0.7799 - recall: 0.7407 - auc: 0.8501 - accuracy: 7.2718e-05 - mae: 0.3321 - val_loss: 0.4584 - val_tp: 4536.0000 - val_fp: 1065.0000 - val_tn: 4935.0000 - val_fn: 1464.0000 - val_binary_accuracy: 0.7893 - val_precision: 0.8099 - val_recall: 0.7560 - val_auc: 0.8682 - val_accuracy: 0.0000e+00 - val_mae: 0.3155\n",
      "Epoch 2/40\n",
      "750/750 [==============================] - 4064s 5s/step - loss: 0.4776 - tp: 8992.1944 - fp: 2469.6671 - tn: 9545.9454 - fn: 3056.1079 - binary_accuracy: 0.7708 - precision: 0.7841 - recall: 0.7473 - auc: 0.8536 - accuracy: 1.1854e-04 - mae: 0.3268 - val_loss: 0.5001 - val_tp: 5366.0000 - val_fp: 2391.0000 - val_tn: 3609.0000 - val_fn: 634.0000 - val_binary_accuracy: 0.7479 - val_precision: 0.6918 - val_recall: 0.8943 - val_auc: 0.8689 - val_accuracy: 0.0000e+00 - val_mae: 0.3317\n",
      "Epoch 3/40\n",
      "750/750 [==============================] - 4055s 5s/step - loss: 0.4839 - tp: 9033.3502 - fp: 2492.8602 - tn: 9477.2290 - fn: 3060.4754 - binary_accuracy: 0.7660 - precision: 0.7795 - recall: 0.7458 - auc: 0.8486 - accuracy: 6.6583e-05 - mae: 0.3292 - val_loss: 0.4547 - val_tp: 4405.0000 - val_fp: 927.0000 - val_tn: 5073.0000 - val_fn: 1595.0000 - val_binary_accuracy: 0.7898 - val_precision: 0.8261 - val_recall: 0.7342 - val_auc: 0.8702 - val_accuracy: 0.0000e+00 - val_mae: 0.3085\n",
      "Epoch 4/40\n",
      "750/750 [==============================] - 4069s 5s/step - loss: 0.4695 - tp: 9005.5433 - fp: 2373.1158 - tn: 9661.6138 - fn: 3023.6418 - binary_accuracy: 0.7766 - precision: 0.7929 - recall: 0.7493 - auc: 0.8601 - accuracy: 2.4122e-05 - mae: 0.3214 - val_loss: 0.4524 - val_tp: 4660.0000 - val_fp: 1158.0000 - val_tn: 4842.0000 - val_fn: 1340.0000 - val_binary_accuracy: 0.7918 - val_precision: 0.8010 - val_recall: 0.7767 - val_auc: 0.8713 - val_accuracy: 0.0000e+00 - val_mae: 0.3091\n",
      "Epoch 5/40\n",
      " 64/750 [=>............................] - ETA: 49:48 - loss: 0.4794 - tp: 743.5156 - fp: 210.2188 - tn: 850.2500 - fn: 276.0156 - binary_accuracy: 0.7622 - precision: 0.7763 - recall: 0.7180 - auc: 0.8518 - accuracy: 0.0000e+00 - mae: 0.3243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4077s 5s/step - loss: 0.4639 - tp: 9077.7057 - fp: 2355.3196 - tn: 9674.1238 - fn: 2956.7656 - binary_accuracy: 0.7785 - precision: 0.7941 - recall: 0.7530 - auc: 0.8638 - accuracy: 2.8721e-04 - mae: 0.3177 - val_loss: 0.4646 - val_tp: 3971.0000 - val_fp: 583.0000 - val_tn: 5417.0000 - val_fn: 2029.0000 - val_binary_accuracy: 0.7823 - val_precision: 0.8720 - val_recall: 0.6618 - val_auc: 0.8733 - val_accuracy: 0.0000e+00 - val_mae: 0.3071\n",
      "Epoch 8/40\n",
      "750/750 [==============================] - 4077s 5s/step - loss: 0.4648 - tp: 9118.2530 - fp: 2363.1877 - tn: 9635.4194 - fn: 2947.0546 - binary_accuracy: 0.7795 - precision: 0.7947 - recall: 0.7570 - auc: 0.8631 - accuracy: 1.3380e-04 - mae: 0.3171 - val_loss: 0.4488 - val_tp: 4522.0000 - val_fp: 974.0000 - val_tn: 5026.0000 - val_fn: 1478.0000 - val_binary_accuracy: 0.7957 - val_precision: 0.8228 - val_recall: 0.7537 - val_auc: 0.8737 - val_accuracy: 0.0000e+00 - val_mae: 0.3051\n",
      "Epoch 9/40\n",
      "750/750 [==============================] - 4074s 5s/step - loss: 0.4616 - tp: 9146.0879 - fp: 2328.3675 - tn: 9679.3369 - fn: 2910.1225 - binary_accuracy: 0.7806 - precision: 0.7972 - recall: 0.7524 - auc: 0.8651 - accuracy: 5.3481e-05 - mae: 0.3149 - val_loss: 0.4448 - val_tp: 4579.0000 - val_fp: 1024.0000 - val_tn: 4976.0000 - val_fn: 1421.0000 - val_binary_accuracy: 0.7962 - val_precision: 0.8172 - val_recall: 0.7632 - val_auc: 0.8755 - val_accuracy: 0.0000e+00 - val_mae: 0.3015\n",
      "Epoch 10/40\n",
      "750/750 [==============================] - 4084s 5s/step - loss: 0.4594 - tp: 9182.2077 - fp: 2341.2929 - tn: 9660.0346 - fn: 2880.3795 - binary_accuracy: 0.7827 - precision: 0.7964 - recall: 0.7612 - auc: 0.8673 - accuracy: 2.0657e-04 - mae: 0.3137 - val_loss: 0.4618 - val_tp: 3942.0000 - val_fp: 549.0000 - val_tn: 5451.0000 - val_fn: 2058.0000 - val_binary_accuracy: 0.7828 - val_precision: 0.8778 - val_recall: 0.6570 - val_auc: 0.8765 - val_accuracy: 0.0000e+00 - val_mae: 0.2996\n",
      "Epoch 11/40\n",
      "750/750 [==============================] - 4072s 5s/step - loss: 0.4564 - tp: 9134.0945 - fp: 2320.6738 - tn: 9697.9814 - fn: 2911.1651 - binary_accuracy: 0.7832 - precision: 0.7998 - recall: 0.7559 - auc: 0.8682 - accuracy: 4.0788e-05 - mae: 0.3107 - val_loss: 0.4430 - val_tp: 4699.0000 - val_fp: 1142.0000 - val_tn: 4858.0000 - val_fn: 1301.0000 - val_binary_accuracy: 0.7964 - val_precision: 0.8045 - val_recall: 0.7832 - val_auc: 0.8769 - val_accuracy: 0.0000e+00 - val_mae: 0.3011\n",
      "Epoch 12/40\n",
      "750/750 [==============================] - 4076s 5s/step - loss: 0.4534 - tp: 9244.6538 - fp: 2300.7856 - tn: 9733.7150 - fn: 2784.7603 - binary_accuracy: 0.7912 - precision: 0.8034 - recall: 0.7711 - auc: 0.8718 - accuracy: 6.2281e-05 - mae: 0.3092 - val_loss: 0.4449 - val_tp: 4375.0000 - val_fp: 805.0000 - val_tn: 5195.0000 - val_fn: 1625.0000 - val_binary_accuracy: 0.7975 - val_precision: 0.8446 - val_recall: 0.7292 - val_auc: 0.8775 - val_accuracy: 0.0000e+00 - val_mae: 0.2975\n",
      "Epoch 13/40\n",
      "750/750 [==============================] - 4075s 5s/step - loss: 0.4552 - tp: 9135.4754 - fp: 2294.0386 - tn: 9753.6258 - fn: 2880.7750 - binary_accuracy: 0.7839 - precision: 0.8002 - recall: 0.7556 - auc: 0.8690 - accuracy: 1.5073e-04 - mae: 0.3090 - val_loss: 0.4418 - val_tp: 4432.0000 - val_fp: 831.0000 - val_tn: 5169.0000 - val_fn: 1568.0000 - val_binary_accuracy: 0.8001 - val_precision: 0.8421 - val_recall: 0.7387 - val_auc: 0.8783 - val_accuracy: 0.0000e+00 - val_mae: 0.2948\n",
      "Epoch 14/40\n",
      "750/750 [==============================] - 4075s 5s/step - loss: 0.4537 - tp: 9148.7643 - fp: 2289.5526 - tn: 9758.9867 - fn: 2866.6112 - binary_accuracy: 0.7853 - precision: 0.8010 - recall: 0.7570 - auc: 0.8699 - accuracy: 1.1826e-04 - mae: 0.3073 - val_loss: 0.4384 - val_tp: 4547.0000 - val_fp: 939.0000 - val_tn: 5061.0000 - val_fn: 1453.0000 - val_binary_accuracy: 0.8007 - val_precision: 0.8288 - val_recall: 0.7578 - val_auc: 0.8792 - val_accuracy: 0.0000e+00 - val_mae: 0.2941\n",
      "Epoch 15/40\n",
      "750/750 [==============================] - 4082s 5s/step - loss: 0.4500 - tp: 9329.3356 - fp: 2282.0559 - tn: 9685.9973 - fn: 2766.5260 - binary_accuracy: 0.7902 - precision: 0.8046 - recall: 0.7729 - auc: 0.8726 - accuracy: 1.5114e-04 - mae: 0.3054 - val_loss: 0.4391 - val_tp: 4634.0000 - val_fp: 1038.0000 - val_tn: 4962.0000 - val_fn: 1366.0000 - val_binary_accuracy: 0.7997 - val_precision: 0.8170 - val_recall: 0.7723 - val_auc: 0.8787 - val_accuracy: 0.0000e+00 - val_mae: 0.2963\n",
      "Epoch 16/40\n",
      "750/750 [==============================] - 4089s 5s/step - loss: 0.4483 - tp: 9213.7790 - fp: 2304.0213 - tn: 9757.5885 - fn: 2788.5260 - binary_accuracy: 0.7885 - precision: 0.8008 - recall: 0.7647 - auc: 0.8737 - accuracy: 7.9528e-05 - mae: 0.3050 - val_loss: 0.4635 - val_tp: 3882.0000 - val_fp: 480.0000 - val_tn: 5520.0000 - val_fn: 2118.0000 - val_binary_accuracy: 0.7835 - val_precision: 0.8900 - val_recall: 0.6470 - val_auc: 0.8798 - val_accuracy: 0.0000e+00 - val_mae: 0.2955\n",
      "Epoch 17/40\n",
      "750/750 [==============================] - 4116s 5s/step - loss: 0.4496 - tp: 9199.3475 - fp: 2263.7510 - tn: 9768.3569 - fn: 2832.4594 - binary_accuracy: 0.7882 - precision: 0.8049 - recall: 0.7628 - auc: 0.8719 - accuracy: 1.0750e-04 - mae: 0.3038 - val_loss: 0.4414 - val_tp: 4337.0000 - val_fp: 734.0000 - val_tn: 5266.0000 - val_fn: 1663.0000 - val_binary_accuracy: 0.8002 - val_precision: 0.8553 - val_recall: 0.7228 - val_auc: 0.8805 - val_accuracy: 0.0000e+00 - val_mae: 0.2915\n",
      "Epoch 18/40\n",
      "750/750 [==============================] - 4075s 5s/step - loss: 0.4527 - tp: 9226.8895 - fp: 2307.5393 - tn: 9701.2903 - fn: 2828.1957 - binary_accuracy: 0.7850 - precision: 0.7990 - recall: 0.7646 - auc: 0.8704 - accuracy: 8.6284e-05 - mae: 0.3054 - val_loss: 0.4419 - val_tp: 4989.0000 - val_fp: 1464.0000 - val_tn: 4536.0000 - val_fn: 1011.0000 - val_binary_accuracy: 0.7937 - val_precision: 0.7731 - val_recall: 0.8315 - val_auc: 0.8815 - val_accuracy: 0.0000e+00 - val_mae: 0.2959\n",
      "Epoch 19/40\n",
      "750/750 [==============================] - 4091s 5s/step - loss: 0.4491 - tp: 9295.0493 - fp: 2294.5899 - tn: 9703.8881 - fn: 2770.3875 - binary_accuracy: 0.7908 - precision: 0.8042 - recall: 0.7711 - auc: 0.8736 - accuracy: 1.1953e-04 - mae: 0.3031 - val_loss: 0.4342 - val_tp: 4667.0000 - val_fp: 1051.0000 - val_tn: 4949.0000 - val_fn: 1333.0000 - val_binary_accuracy: 0.8013 - val_precision: 0.8162 - val_recall: 0.7778 - val_auc: 0.8813 - val_accuracy: 0.0000e+00 - val_mae: 0.2913\n",
      "Epoch 20/40\n",
      "750/750 [==============================] - 4083s 5s/step - loss: 0.4417 - tp: 9281.3742 - fp: 2269.1558 - tn: 9758.3196 - fn: 2755.0652 - binary_accuracy: 0.7921 - precision: 0.8047 - recall: 0.7743 - auc: 0.8775 - accuracy: 1.3171e-04 - mae: 0.3001 - val_loss: 0.4346 - val_tp: 4745.0000 - val_fp: 1122.0000 - val_tn: 4878.0000 - val_fn: 1255.0000 - val_binary_accuracy: 0.8019 - val_precision: 0.8088 - val_recall: 0.7908 - val_auc: 0.8814 - val_accuracy: 0.0000e+00 - val_mae: 0.2926\n",
      "Epoch 21/40\n",
      "750/750 [==============================] - 4101s 5s/step - loss: 0.4488 - tp: 9328.3049 - fp: 2283.6085 - tn: 9690.6618 - fn: 2761.3395 - binary_accuracy: 0.7890 - precision: 0.8027 - recall: 0.7717 - auc: 0.8728 - accuracy: 9.1945e-05 - mae: 0.3026 - val_loss: 0.4388 - val_tp: 4331.0000 - val_fp: 711.0000 - val_tn: 5289.0000 - val_fn: 1669.0000 - val_binary_accuracy: 0.8017 - val_precision: 0.8590 - val_recall: 0.7218 - val_auc: 0.8823 - val_accuracy: 0.0000e+00 - val_mae: 0.2885\n",
      "Epoch 22/40\n",
      "750/750 [==============================] - 4073s 5s/step - loss: 0.4427 - tp: 9324.0586 - fp: 2262.9028 - tn: 9746.7297 - fn: 2730.2237 - binary_accuracy: 0.7933 - precision: 0.8063 - recall: 0.7750 - auc: 0.8769 - accuracy: 1.2629e-04 - mae: 0.2989 - val_loss: 0.4361 - val_tp: 4922.0000 - val_fp: 1334.0000 - val_tn: 4666.0000 - val_fn: 1078.0000 - val_binary_accuracy: 0.7990 - val_precision: 0.7868 - val_recall: 0.8203 - val_auc: 0.8825 - val_accuracy: 0.0000e+00 - val_mae: 0.2926\n",
      "Epoch 23/40\n",
      "750/750 [==============================] - 4059s 5s/step - loss: 0.4415 - tp: 9263.7111 - fp: 2205.0679 - tn: 9855.7244 - fn: 2739.4115 - binary_accuracy: 0.7941 - precision: 0.8079 - recall: 0.7694 - auc: 0.8775 - accuracy: 1.1446e-04 - mae: 0.2992 - val_loss: 0.4406 - val_tp: 5016.0000 - val_fp: 1499.0000 - val_tn: 4501.0000 - val_fn: 984.0000 - val_binary_accuracy: 0.7931 - val_precision: 0.7699 - val_recall: 0.8360 - val_auc: 0.8827 - val_accuracy: 0.0000e+00 - val_mae: 0.2940\n",
      "Epoch 24/40\n",
      "608/750 [=======================>......] - ETA: 10:14 - loss: 0.4383 - tp: 7531.8882 - fp: 1762.6151 - tn: 8004.9326 - fn: 2188.5641 - binary_accuracy: 0.7941 - precision: 0.8068 - recall: 0.7714 - auc: 0.8796 - accuracy: 1.3648e-04 - mae: 0.2969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 4095s 5s/step - loss: 0.4328 - tp: 9395.1238 - fp: 2221.4727 - tn: 9779.5486 - fn: 2667.7696 - binary_accuracy: 0.7983 - precision: 0.8109 - recall: 0.7802 - auc: 0.8833 - accuracy: 1.2979e-04 - mae: 0.2940 - val_loss: 0.4403 - val_tp: 4275.0000 - val_fp: 653.0000 - val_tn: 5347.0000 - val_fn: 1725.0000 - val_binary_accuracy: 0.8018 - val_precision: 0.8675 - val_recall: 0.7125 - val_auc: 0.8834 - val_accuracy: 0.0000e+00 - val_mae: 0.2875\n",
      "Epoch 27/40\n",
      "714/750 [===========================>..] - ETA: 2:36 - loss: 0.4374 - tp: 8877.9104 - fp: 2111.9258 - tn: 9336.7843 - fn: 2553.3796 - binary_accuracy: 0.7967 - precision: 0.8091 - recall: 0.7767 - auc: 0.8803 - accuracy: 1.1877e-04 - mae: 0.2961"
     ]
    }
   ],
   "source": [
    "#train\n",
    "history = model.fit(training_set, epochs=40, validation_data=validation_set, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>val_tp</th>\n",
       "      <th>val_fp</th>\n",
       "      <th>val_tn</th>\n",
       "      <th>val_fn</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.607360</td>\n",
       "      <td>14875.0</td>\n",
       "      <td>6966.0</td>\n",
       "      <td>17034.0</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>0.664771</td>\n",
       "      <td>0.681059</td>\n",
       "      <td>0.619792</td>\n",
       "      <td>0.724288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>5585.0</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>0.697167</td>\n",
       "      <td>0.870150</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.821266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561719</td>\n",
       "      <td>16014.0</td>\n",
       "      <td>5983.0</td>\n",
       "      <td>18017.0</td>\n",
       "      <td>7986.0</td>\n",
       "      <td>0.708979</td>\n",
       "      <td>0.728008</td>\n",
       "      <td>0.667250</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4184.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>4932.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>0.759667</td>\n",
       "      <td>0.796649</td>\n",
       "      <td>0.697333</td>\n",
       "      <td>0.837554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540536</td>\n",
       "      <td>16487.0</td>\n",
       "      <td>5631.0</td>\n",
       "      <td>18369.0</td>\n",
       "      <td>7513.0</td>\n",
       "      <td>0.726167</td>\n",
       "      <td>0.745411</td>\n",
       "      <td>0.686958</td>\n",
       "      <td>0.802186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>5128.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.760667</td>\n",
       "      <td>0.821018</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.524037</td>\n",
       "      <td>16791.0</td>\n",
       "      <td>5403.0</td>\n",
       "      <td>18597.0</td>\n",
       "      <td>7209.0</td>\n",
       "      <td>0.737250</td>\n",
       "      <td>0.756556</td>\n",
       "      <td>0.699625</td>\n",
       "      <td>0.817910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4227.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5022.0</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>0.770750</td>\n",
       "      <td>0.812104</td>\n",
       "      <td>0.704500</td>\n",
       "      <td>0.853143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516342</td>\n",
       "      <td>16986.0</td>\n",
       "      <td>5305.0</td>\n",
       "      <td>18695.0</td>\n",
       "      <td>7014.0</td>\n",
       "      <td>0.743354</td>\n",
       "      <td>0.762012</td>\n",
       "      <td>0.707750</td>\n",
       "      <td>0.824245</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>4515.0</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>4804.0</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>0.776583</td>\n",
       "      <td>0.790580</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.856080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss       tp      fp       tn      fn  binary_accuracy  precision  \\\n",
       "0  0.607360  14875.0  6966.0  17034.0  9125.0         0.664771   0.681059   \n",
       "1  0.561719  16014.0  5983.0  18017.0  7986.0         0.708979   0.728008   \n",
       "2  0.540536  16487.0  5631.0  18369.0  7513.0         0.726167   0.745411   \n",
       "3  0.524037  16791.0  5403.0  18597.0  7209.0         0.737250   0.756556   \n",
       "4  0.516342  16986.0  5305.0  18695.0  7014.0         0.743354   0.762012   \n",
       "\n",
       "     recall       auc  accuracy  ...  val_tp  val_fp  val_tn  val_fn  \\\n",
       "0  0.619792  0.724288  0.000000  ...  2781.0   415.0  5585.0  3219.0   \n",
       "1  0.667250  0.780652  0.000000  ...  4184.0  1068.0  4932.0  1816.0   \n",
       "2  0.686958  0.802186  0.000000  ...  4000.0   872.0  5128.0  2000.0   \n",
       "3  0.699625  0.817910  0.000000  ...  4227.0   978.0  5022.0  1773.0   \n",
       "4  0.707750  0.824245  0.000021  ...  4515.0  1196.0  4804.0  1485.0   \n",
       "\n",
       "   val_binary_accuracy  val_precision  val_recall   val_auc  val_accuracy  \\\n",
       "0             0.697167       0.870150    0.463500  0.821266           0.0   \n",
       "1             0.759667       0.796649    0.697333  0.837554           0.0   \n",
       "2             0.760667       0.821018    0.666667  0.847191           0.0   \n",
       "3             0.770750       0.812104    0.704500  0.853143           0.0   \n",
       "4             0.776583       0.790580    0.752500  0.856080           0.0   \n",
       "\n",
       "    val_mae  \n",
       "0  0.383525  \n",
       "1  0.360385  \n",
       "2  0.351955  \n",
       "3  0.346838  \n",
       "4  0.339253  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "training_info = pd.DataFrame(history.history)\n",
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info.to_csv('./model_checkpoints/uk_not_uk/more_epochs_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16169 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_folder = '../images/uk_not_uk/test'\n",
    "preprocessor = keras.applications.resnet50.preprocess_input\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocessor)\n",
    "test_set = test_data_generator.flow_from_directory(test_folder, class_mode='binary',target_size=(img_height,img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_checkpoints/uk_not_uk/location_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/506 [============================>.] - ETA: 22s - loss: 1.2298 - tp: 3602.0000 - fp: 55.0000 - tn: 128.0000 - fn: 12087.0000 - binary_accuracy: 0.2350 - precision: 0.9850 - recall: 0.2296 - auc: 0.4453 - accuracy: 0.0000e+00 - mae: 0.6401"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-467240053c36>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-467240053c36>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    hist = pd.read_csv(./model_checkpoints/uk_not_uk/location_classifier.csv)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist = pd.read_csv(./model_checkpoints/uk_not_uk/location_classifier.csv)\n",
    "hist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
